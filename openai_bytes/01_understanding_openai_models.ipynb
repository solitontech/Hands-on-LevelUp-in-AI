{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc60a65",
   "metadata": {},
   "source": [
    "# Byte #1: Understanding OpenAI Models üß†\n",
    "\n",
    "**‚è±Ô∏è Time to Complete: 5-10 minutes**\n",
    "\n",
    "Welcome to SPL Season 7‚Äôs hero HQ! Nearly 130 super-teams are suiting up, and you‚Äôll soon receive your API key plus a budget to explore the five competition-ready OpenAI models. Use this byte to scout each model‚Äôs powers so your squad can leap into the bot build sprint later this week like seasoned defenders of the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fbd9c9",
   "metadata": {},
   "source": [
    "## What Are These Models?\n",
    "\n",
    "Think of AI models as different heroes on your roster‚Äîeach brings unique strengths, speeds, and specialties. Choosing the right model is like deploying the perfect hero for the mission at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81f311",
   "metadata": {},
   "source": [
    "## The Five OpenAI Heroes Compared\n",
    "\n",
    "| Hero Model | Speed | Cost | Intelligence | Best Mission | Max Tokens | Reasoning Ability |\n",
    "|------------|-------|------|-------------|--------------|------------|-------------------|\n",
    "| **GPT 5-nano** | ‚ö°‚ö°‚ö°‚ö° Very Fast | üí∞ Very Low | üß† Basic | Quick intel, low-cost utilities | 16K | Basic |\n",
    "| **GPT 5-mini** | ‚ö°‚ö°‚ö° Fast | üí∞ Low | üß†üß†üß† Good | Balanced all-rounder support | 32K | Good |\n",
    "| **GPT 4.1-mini** | ‚ö°‚ö° Moderate | üí∞üí∞ Medium | üß†üß†üß†üß† Very Good | Tactical reasoning, coding assists | 64K | Very Good |\n",
    "| **GPT 4o** | ‚ö° Moderate | üí∞üí∞ Medium | üß†üß†üß† Good | Long-form strategy briefs, multimodal | 128K | Good |\n",
    "| **GPT 4.1** | ‚ö° Slower | üí∞üí∞üí∞ High | üß†üß†üß†üß†üß† Excellent | Precision problem-solving, boss fights | 128K | Excellent |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c005f0d",
   "metadata": {},
   "source": [
    "## Key Concepts Explained\n",
    "\n",
    "### üîπ What are Tokens?\n",
    "\n",
    "Tokens are the energy units your models spend when they speak or think. They‚Äôre pieces of words the model processes‚Äîimagine syllables or fragments.\n",
    "\n",
    "**Examples:**\n",
    "- \"Hello\" = 1 token\n",
    "- \"ChatGPT is amazing!\" = 5 tokens\n",
    "- \"OpenAI's GPT-4o model\" = 7 tokens\n",
    "\n",
    "**Why it matters:** Energy isn‚Äôt infinite. More tokens = higher cost.\n",
    "\n",
    "**Rule of thumb:** 1 token ‚âà 4 characters or ‚âà 0.75 words in English\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Prompting and Reasoning\n",
    "\n",
    "- For best results, learn how to write effective prompts: [OpenAI Prompting Guide](https://platform.openai.com/docs/guides/prompting)\n",
    "- For deeper understanding of how models reason, see: [OpenAI Reasoning Guide](https://platform.openai.com/docs/guides/reasoning)\n",
    "\n",
    "These official guides explain how to structure your requests and how OpenAI models approach reasoning, planning, and instruction following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ed046",
   "metadata": {},
   "source": [
    "### üîπ Peek at the Actual Tokens\n",
    "\n",
    "Want to inspect the exact token chunks you send a model? Install `tiktoken` (`uv pip install tiktoken`) and run the next cell to see each token‚Äôs id and decoded text. This helps explain why token counts differ across prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8997bc2",
   "metadata": {},
   "source": [
    "#### Quick Setup\n",
    "\n",
    "> ‚öôÔ∏è From the repo root, activate your venv and run `uv pip install -e .` using cli before launching this notebook so the OpenAI SDK and other helpers are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae01f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Swap hero models or tweak the prompt to see how tokenization changes for each combo.\n",
    "\n",
    "model_name = \"gpt-4.1-mini\"  # Adjust to match the hero you plan to call\n",
    "prompt = \"Strategist, assemble the SPL recon squad for tonight's mission.\"\n",
    "\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "except KeyError:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")  # Fallback for newer hero families\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "token_strings = [encoding.decode([token]) for token in tokens]\n",
    "\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(\"Index | Token ID | Piece\")\n",
    "print(\"------|----------|------\")\n",
    "for idx, (token_id, token_str) in enumerate(zip(tokens, token_strings), start=1):\n",
    "    print(f\"{idx:>5} | {token_id:>8} | {token_str!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058a378",
   "metadata": {},
   "source": [
    "### üîπ What is Reasoning?\n",
    "\n",
    "Reasoning models (like GPT 4.1 and GPT 4.1-mini) are the tacticians of your squad. They don‚Äôt just react‚Äîthey plot a plan, consider angles, and then strike.\n",
    "\n",
    "**Example:**\n",
    "- **Regular model:** Fires off a quick quip.\n",
    "- **Reasoning model:** Narrates the battle plan: \"First, I‚Äôll assess X... then counter Y... therefore our winning move is Z.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69289c4",
   "metadata": {},
   "source": [
    "### üîê Configure Your OpenAI API Key\n",
    "\n",
    "- Before you run any of the API examples, confirm that your project-wide `.env` file contains a valid `OPENAI_API_KEY`. \n",
    "- `OPENAI_API_KEY` variable name is the standard that the OpenAI SDK expects‚Äîstick to it exactly so the client can discover your key without extra wiring. \n",
    "- To generate your api key, follow the step-by-step guide at [Create Your OpenAI API key](https://spl.solitontech.ai/docs/setup-tools/creating-openai-api-key/) before continuing.\n",
    "\n",
    "\n",
    "```\n",
    "# .env\n",
    "OPENAI_API_KEY=\"sk-live-or-team-key\"\n",
    "```\n",
    "\n",
    "- Once the key is in place‚Äîand only with this exact name‚Äîthe SDK loads it automatically when you instantiate `OpenAI()`, so no additional configuration is required.\n",
    "- If the variable is missing, add it now and restart the kernel so the updated environment loads. Avoid committing this file to version control‚Äîyou only want it stored locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1e382",
   "metadata": {},
   "source": [
    "## Quick Code Sample: Checking Your Hero Roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install python-dotenv with `uv add python-dotenv`.\") from exc\n",
    "\n",
    "# Load environment variables from the root .env file if available\n",
    "try:\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Loaded hero credentials from .env\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to load .env file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# List all available models\n",
    "models = client.models.list()\n",
    "\n",
    "# Print model IDs\n",
    "for model in models.data:\n",
    "    print(f\"Model: {model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca69169",
   "metadata": {},
   "source": [
    "## Real-World Hero Missions\n",
    "\n",
    "Deploy these heroes where they shine so your squad can move faster from idea to implementation.\n",
    "\n",
    "- **GPT 5-nano** ‚Üí Instant support replies, automated status pings, lightweight monitoring summaries during hackathons.\n",
    "- **GPT 5-mini** ‚Üí Daily stand-up notes, onboarding walkthroughs, internal docs clean-up while keeping tone on brand.\n",
    "- **GPT 4.1-mini** ‚Üí Guided coding helpers, structured bug triage, decision trees that justify trade-offs for product leads.\n",
    "- **GPT 4o** ‚Üí Multimodal pitch decks, UX walkthroughs with screenshots, campaign brainstorms that mix text plus visuals.\n",
    "- **GPT 4.1** ‚Üí Deep dive architecture reviews, compliance-ready policy drafting, multi-step strategy plans that require rigorous reasoning.\n",
    "\n",
    "> Tip: Pilot a mission with one hero, review cost/quality, then rotate in another model to see which squadmate excels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d6a49",
   "metadata": {},
   "source": [
    "## üí° Hero Dispatch Guide\n",
    "\n",
    "**Ask yourself:**\n",
    "\n",
    "1. **Need a super-fast, lightweight response?** ‚Üí Deploy `gpt-5-nano`\n",
    "\n",
    "2. **Want a balanced partner for everyday missions?** ‚Üí Call `gpt-5-mini`\n",
    "\n",
    "3. **Facing complex puzzles or reasoning-heavy villains?** ‚Üí Summon `gpt-4.1`\n",
    "\n",
    "4. **Need sharp reasoning on a tighter budget?** ‚Üí Team up with `gpt-4.1-mini`\n",
    "\n",
    "5. **Handling epic story arcs or multimodal intel?** ‚Üí Bring in `gpt-4o`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c82218",
   "metadata": {},
   "source": [
    "## Cost Example (Hero Energy Budget)\n",
    "\n",
    "Imagine your team spends 1 million tokens of hero energy:\n",
    "\n",
    "| Hero Model | Input Cost (per 1M tokens) | Output Cost (per 1M tokens) | Total (‚âà1M tokens) |\n",
    "|------------|----------------------------|-----------------------------|--------------------|\n",
    "| **GPT 5-nano** | $0.05 | $0.40 | ~$0.45 |\n",
    "| **GPT 5-mini** | $0.25 | $2.00 | ~$2.25 |\n",
    "| **GPT 4.1-mini** | $0.40 | $1.60 | ~$2.00 |\n",
    "| **GPT 4o** | $5.00 | $15.00 | ~$20.00 |\n",
    "| **GPT 4.1** | $2.00 | $8.00 | ~$10.00 |\n",
    "\n",
    "*Note: Prices change‚Äîcheck the [OpenAI Pricing](https://platform.openai.com/docs/pricing/) board before launching your mission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f578ee",
   "metadata": {},
   "source": [
    "## üéØ Hero Briefing Recap\n",
    "\n",
    "‚úì Different heroes = different powers\n",
    "\n",
    "‚úì Tokens = hero energy reserves\n",
    "\n",
    "‚úì Reasoning heroes map out battle plans\n",
    "\n",
    "‚úì Match the hero to the mission and budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257db2c",
   "metadata": {},
   "source": [
    "## Part 2: Making API Calls üí¨\n",
    "\n",
    "**‚è±Ô∏è Time to Complete: 5-10 minutes**\n",
    "\n",
    "With your roster scouted, it‚Äôs time to radio mission control. You already have your team‚Äôs API key secured from the Week 1 briefing, so let‚Äôs learn how to call each hero into action with real API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53016eff",
   "metadata": {},
   "source": [
    "### How to Talk to the Hero Team\n",
    "\n",
    "You communicate with OpenAI models by sending message payloads‚Äîthink of it as dispatching mission briefings to your AI squad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed43e6",
   "metadata": {},
   "source": [
    "### Gear Up the Command Line Tools\n",
    "\n",
    "If a cell complains about a missing package, open a terminal at the repo root, activate your environment and run `uv pip install -e .` to refresh the editable install. That pulls in the OpenAI SDK, `python-dotenv`, and the other helpers this course expects.\n",
    "\n",
    "Prefer to patch things package-by-package while debugging? Use the targeted install instead:\n",
    "```bash\n",
    "# install with uv (only when a dependency is missing)\n",
    "uv add openai python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8600a9",
   "metadata": {},
   "source": [
    "### Your First API Call ‚Äì Summon a Hero\n",
    "\n",
    "With the client initialized, send a mission ping to `gpt-5-nano` and review the heroic briefing it returns. The Responses API expects each message chunk to declare its type‚Äîtext prompts from you use `input_text`, while model replies are returned as `output_text`.\n",
    "\n",
    "Curious about everything the Responses endpoint can do? Explore the [API reference](https://platform.openai.com/docs/api-reference/responses/create) and note how the official `openai` Python library wraps those HTTP calls so you can focus on crafting prompts instead of hand-rolling requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the client (automatically picks up OPENAI_API_KEY from your environment)\n",
    "client = OpenAI()\n",
    "\n",
    "# Send a simple message\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"Which hero model should lead our SPL recon squad?\"}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the answer\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9b93d",
   "metadata": {},
   "source": [
    "### Understand the Mission Debrief\n",
    "\n",
    "Every response includes the hero‚Äôs answer plus telemetry‚Äîperfect for debriefs, analytics, and cost control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa70c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"Describe your hero persona in exactly 10 words.\"}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FULL RESPONSE STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. The actual answer\n",
    "answer = response.output_text\n",
    "print(f\"Answer: {answer}\")\n",
    "\n",
    "# 2. Token usage (this is how you calculate cost!)\n",
    "print(\"\\nTokens used:\")\n",
    "print(f\"  - Input tokens: {response.usage.input_tokens}\")\n",
    "print(f\"  - Output tokens: {response.usage.output_tokens}\")\n",
    "print(f\"  - Total tokens: {response.usage.total_tokens}\")\n",
    "\n",
    "# 3. Model used\n",
    "print(f\"\\nModel: {response.model}\")\n",
    "\n",
    "# 4. Finish reason\n",
    "print(f\"Finish reason: {response.output[0].summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81554f",
   "metadata": {},
   "source": [
    "### Calculate Mission Cost from Token Usage\n",
    "\n",
    "Use the energy table from Part 1 to estimate the spend for each hero deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(input_tokens, output_tokens, model=\"gpt-5-nano\"):\n",
    "    \"\"\"Calculate the cost of an API call\"\"\"\n",
    "    pricing = {\n",
    "        \"gpt-5-nano\": {\"input\": 0.05, \"output\": 0.40},\n",
    "        \"gpt-5-mini\": {\"input\": 0.25, \"output\": 2.00},\n",
    "        \"gpt-4.1-mini\": {\"input\": 0.40, \"output\": 1.60},\n",
    "        \"gpt-4o\": {\"input\": 5.00, \"output\": 15.00},\n",
    "        \"gpt-4.1\": {\"input\": 2.00, \"output\": 8.00},\n",
    "    }\n",
    "    input_cost = (input_tokens / 1_000_000) * pricing[model][\"input\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * pricing[model][\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    return {\n",
    "        \"input_cost\": input_cost,\n",
    "        \"output_cost\": output_cost,\n",
    "        \"total_cost\": total_cost,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53912f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate this cell to plug in token counts from other calls and compare model costs.\n",
    "cost = calculate_cost(15, 14, \"gpt-5-nano\")\n",
    "print(\"Cost breakdown for gpt-5-nano call (1M-token pricing):\")\n",
    "print(f\"  Input cost : ${cost['input_cost']:.6f}\")\n",
    "print(f\"  Output cost: ${cost['output_cost']:.6f}\")\n",
    "print(f\"  Total cost : ${cost['total_cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac37f",
   "metadata": {},
   "source": [
    "### Build a Hero Briefing Log\n",
    "\n",
    "Maintain the conversation history so your hero can reference earlier intel‚Äîjust like reviewing previous mission reports before re-engaging.\n",
    "\n",
    "The Conversations API lets you open a single mission log on OpenAI's servers and keep adding turns without resending the full script. You create a conversation once, append new `message` items as the briefing evolves, and then call the Responses endpoint with `conversation=<conversation_id>` so the strategist can reply in full context. This approach shines for longer arcs where you want durable memory, built-in usage tracking, or tooling that needs to pick up right where the last squad left off.\n",
    "\n",
    "Read the full playbook in the [Conversations API reference](https://platform.openai.com/docs/api-reference/conversations/create) to see every field you can log and how conversations work with streaming, tools, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Conversations API keeps the mission log on OpenAI's side so you don't need to resend history each turn.\n",
    "conversation = client.conversations.create(\n",
    "    metadata={\"topic\": \"spl-hero-recon\"},\n",
    "    items=[\n",
    "        # You'll learn more about how these roles shape the conversation later on.\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"You are the SPL mission strategist guiding our hero squad.\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"What hero trait makes gpt-5-nano perfect for recon missions?\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    conversation=conversation.id,\n",
    "    input=[],\n",
    ")\n",
    "\n",
    "assistant_reply = response.output_text\n",
    "print(\"Strategist:\", assistant_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e181fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add another user turn to the same conversation and let the model build on its prior answer.\n",
    "client.conversations.items.create(\n",
    "    conversation_id=conversation.id,\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Give me a example of using that hero in Python.\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "follow_up = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    conversation=conversation.id,\n",
    "    input=[],\n",
    ")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nStrategist:\", follow_up.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf399749",
   "metadata": {},
   "source": [
    "### Understand Message Roles\n",
    "\n",
    "Messages include a `role` so the model knows who is speaking and how to behave. Think of roles as stage directions:\n",
    "- `system` sets the overall persona or guardrails (the director‚Äôs notes).\n",
    "- `user` captures each question or instruction you send (the live prompt).\n",
    "- `assistant` stores prior AI replies so the model remembers context.\n",
    "\n",
    "Being explicit with roles keeps longer conversations coherent and helps the model follow your intended tone and constraints. Curious about deeper guidance? Dive into the [message roles and instruction following playbook](https://platform.openai.com/docs/guides/text#message-roles-and-instruction-following)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_text\",\n",
    "                \"text\": \"You are Captain Aria, leader of the SPL hero initiative.\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_text\",\n",
    "                \"text\": \"Brief me on the mission objective.\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"output_text\",\n",
    "                \"text\": \"Commander, our goal is to build a bot that dominates the arena.\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b9602",
   "metadata": {},
   "source": [
    "### Practical Example: Token Counter with Cost\n",
    "\n",
    "Wrap everything into a helper that times the call, reports token usage, and reuses the `calculate_cost` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7968efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def ask_question(question, model=\"gpt-5-mini\"):\n",
    "    \"\"\"Ask a question and display detailed info\"\"\"\n",
    "    start_time = time.time()\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": question}],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    answer = response.output_text\n",
    "    input_tokens = response.usage.input_tokens\n",
    "    output_tokens = response.usage.output_tokens\n",
    "    total_tokens = response.usage.total_tokens\n",
    "    time_taken = end_time - start_time\n",
    "    cost = calculate_cost(input_tokens, output_tokens, model)\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ANSWER: {answer}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä STATS:\")\n",
    "    print(f\"  Model: {model}\")\n",
    "    print(f\"  Input tokens: {input_tokens}\")\n",
    "    print(f\"  Output tokens: {output_tokens}\")\n",
    "    print(f\"  Total tokens: {total_tokens}\")\n",
    "    print(f\"  Time taken: {time_taken:.2f} seconds\")\n",
    "    print(f\"  Cost: ${cost['total_cost']:.6f}\")\n",
    "    print(\"=\" * 60)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate this cell and swap in different models to compare their style and cost side-by-side.\n",
    "response = ask_question(\"Which hero model should command the SPL defense grid?\", model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c81f1",
   "metadata": {},
   "source": [
    "### Practice Missions\n",
    "\n",
    "1. Ask \"What is the capital of France?\" and log the token count.\n",
    "2. Run a three-turn planning session that covers Python basics, project ideas, and next steps.\n",
    "3. Ask the same question to `gpt-5-nano` and `gpt-4.1`‚Äîcompare answer quality and token usage.\n",
    "4. After running the notebook, review your account usage following the steps in https://spl.solitontech.ai/docs/setup-tools/creating-openai-api-key/#26-check-usage to see how many tokens you consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcc63b",
   "metadata": {},
   "source": [
    "### Advanced: Expand Your Hero Arsenal\n",
    "\n",
    "Once you‚Äôre comfortable with chat missions, explore file uploads, embeddings, or batch jobs to supercharge your tooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc564f99",
   "metadata": {},
   "source": [
    "### Part 2 Recap\n",
    "\n",
    "‚úì API calls are mission briefings to your heroes\n",
    "\n",
    "‚úì Token usage tracks energy spend‚Äîmonitor it to stay under budget\n",
    "\n",
    "‚úì Conversation history and roles keep the squad aligned\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-level-up-in-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
