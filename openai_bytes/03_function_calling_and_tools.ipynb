{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50920683",
   "metadata": {},
   "source": [
    "# Byte #3: Function Calling with OpenAI (Agents in Action) ðŸ”§\n",
    "\n",
    "**â±ï¸ Time to Complete: 10-15 minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc11533",
   "metadata": {},
   "source": [
    "Welcome back to hero HQ! By now you can talk to models, reason through async calls, and keep conversations alive. In this byte you will teach an assistant to reach beyond the model and use trusted toolsâ€”perfect for building production-ready copilots that can look up data, run calculations, or trigger workflows on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66519459",
   "metadata": {},
   "source": [
    "## Why Function Calling?\n",
    "\n",
    "Models donâ€™t automatically know your private knowledge base, inventory numbers, or the latest sensor readings. Function calling lets you expose safe, well-defined functions so an assistant can fetch facts, perform actions, or orchestrate other systemsâ€”all while you stay in control of what can be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14961a31",
   "metadata": {},
   "source": [
    "### Core Concepts\n",
    "\n",
    "- **Tool** â†’ A function you register with the model (JSON schema describes inputs).\n",
    "- **Tool call** â†’ The model requests a tool by name with arguments when it needs external help.\n",
    "- **Tool result** â†’ Your application executes the function, then replies with the output so the model can finish its answer.\n",
    "- **Guardrails** â†’ You decide which tools exist and validate every call before running it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0b8ba",
   "metadata": {},
   "source": [
    "## Setup Checklist\n",
    "\n",
    "1. Activate your project virtual environment.\n",
    "2. Install dependencies once with `uv pip install -e .` so the OpenAI SDK and dotenv helper are ready.\n",
    "3. Confirm your `.env` file has a valid `OPENAI_API_KEY` (and restart the kernel after edits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bab474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Load environment variables so the OpenAI SDK can find OPENAI_API_KEY\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "print(\"âœ… OpenAI client ready for tool calling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e99f88",
   "metadata": {},
   "source": [
    "## Step 1: Define a Simple Tool\n",
    "\n",
    "To keep the flow focused on the Responses API mechanics, we'll expose one playful function: a horoscope generator that always returns a friendly prediction for the requested zodiac sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horoscope(sign: str) -> dict:\n",
    "    \"\"\"Return a whimsical horoscope for the requested astrological sign.\"\"\"\n",
    "    message = f\"{sign}: Next Tuesday you will befriend a baby otter.\"\n",
    "    return {\"sign\": sign, \"horoscope\": message}\n",
    "\n",
    "AVAILABLE_TOOLS = {\"get_horoscope\": get_horoscope}\n",
    "print(\"ðŸ› ï¸ Local tools registered: \" + \", \".join(AVAILABLE_TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59a896",
   "metadata": {},
   "source": [
    "## Step 2: Describe the Tool for the API\n",
    "\n",
    "The model needs a contract for each function. We'll provide a concise JSON Schema so the assistant knows it can call `get_horoscope` with a single `sign` string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_horoscope\",\n",
    "        \"description\": \"Get today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"An astrological sign like Taurus or Aquarius.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sign\"],\n",
    "        },\n",
    "    },\n",
    " ]\n",
    "print(json.dumps(tools, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44cc74",
   "metadata": {},
   "source": [
    "## Step 3: Call the Model with the Horoscope Tool\n",
    "\n",
    "We will ask the assistant for an Aquarius horoscope. The model may call our tool, so we'll capture that request, execute the Python function, and return the result so it can finish the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is my horoscope? I am an Aquarius.\"\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": question}\n",
    "        ],\n",
    "    }\n",
    " ]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    " )\n",
    "\n",
    "def _serialize_output_item(item):\n",
    "    \"\"\"Convert SDK output objects into dictionaries we can send back to the API.\"\"\"\n",
    "    payload = json.loads(item.model_dump_json())\n",
    "    payload.pop(\"status\", None)\n",
    "    return payload\n",
    "\n",
    "input_list += [_serialize_output_item(item) for item in response.output]\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\" and item.name == \"get_horoscope\":\n",
    "        args = item.arguments\n",
    "        if isinstance(args, str):\n",
    "            args = json.loads(args or \"{}\")\n",
    "        elif args is None:\n",
    "            args = {}\n",
    "        horoscope = get_horoscope(**args)\n",
    "        input_list.append({\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": item.call_id,\n",
    "            \"output\": json.dumps(horoscope),\n",
    "        })\n",
    "\n",
    "print(\"Final input:\")\n",
    "print(json.dumps(input_list, indent=2))\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"Respond only with a horoscope generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    " )\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + (response.output_text or \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1080b",
   "metadata": {},
   "source": [
    "### Flow Recap\n",
    "\n",
    "1. **Send** the user request along with tool schemas.\n",
    "2. **Inspect** the assistant outputâ€”if it returns a `tool_call`, you own the execution.\n",
    "3. **Respond** with a `tool_result` payload tied to the tool call ID.\n",
    "4. **Read** the assistantâ€™s final message that now includes the fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a8382",
   "metadata": {},
   "source": [
    "## Step 4: Wrap It in a Helper\n",
    "\n",
    "Encapsulate the pattern so future notebooks or services can reuse it. The helper below runs the complete loop and returns both structured data and the assistant text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_arguments(raw_args):\n",
    "    if isinstance(raw_args, str):\n",
    "        raw_args = raw_args or \"{}\"\n",
    "        return json.loads(raw_args)\n",
    "    return raw_args or {}\n",
    "\n",
    "def _serialize_output_item(item):\n",
    "    payload = json.loads(item.model_dump_json())\n",
    "    payload.pop(\"status\", None)\n",
    "    return payload\n",
    "\n",
    "def run_assistant(prompt: str, model: str = \"gpt-5-nano\") -> dict:\n",
    "    \"\"\"Run the documented Responses API tool-calling loop and return structured data.\"\"\"\n",
    "    transcript = []\n",
    "    input_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    initial = client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(initial)\n",
    "    input_list += [_serialize_output_item(item) for item in initial.output]\n",
    "\n",
    "    call_outputs = []\n",
    "    for item in initial.output:\n",
    "        if item.type == \"function_call\":\n",
    "            tool_fn = AVAILABLE_TOOLS.get(item.name)\n",
    "            args = _parse_arguments(item.arguments)\n",
    "            if not tool_fn:\n",
    "                result_payload = {\"success\": False, \"error\": f\"Unknown tool: {item.name}\"}\n",
    "            else:\n",
    "                try:\n",
    "                    result_payload = tool_fn(**args)\n",
    "                except TypeError as exc:\n",
    "                    result_payload = {\"success\": False, \"error\": str(exc)}\n",
    "            serialized_result = json.dumps(result_payload)\n",
    "            call_outputs.append({\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": serialized_result,\n",
    "            })\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": serialized_result,\n",
    "            })\n",
    "\n",
    "    final = client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        instructions=\"Summarize the tool findings clearly for the user.\",\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(final)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"input_list\": input_list,\n",
    "        \"tool_outputs\": call_outputs,\n",
    "        \"assistant_text\": final.output_text,\n",
    "        \"responses\": transcript,\n",
    "    }\n",
    "\n",
    "demo = run_assistant(\"Please share today's Virgo horoscope.\")\n",
    "print(demo[\"assistant_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b724e03",
   "metadata": {},
   "source": [
    "## Optional: Async Version\n",
    "\n",
    "Large agents often run in event loops. The async helper mirrors the same flow but awaits each network hop so you can orchestrate multiple assistants concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "async_client = AsyncOpenAI()\n",
    "\n",
    "async def run_assistant_async(prompt: str, model: str = \"gpt-5-nano\") -> dict:\n",
    "    \"\"\"Async variant that mirrors the cumulative input workflow.\"\"\"\n",
    "    transcript = []\n",
    "    input_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    initial = await async_client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(initial)\n",
    "    input_list += [_serialize_output_item(item) for item in initial.output]\n",
    "\n",
    "    call_outputs = []\n",
    "    for item in initial.output:\n",
    "        if item.type == \"function_call\":\n",
    "            tool_fn = AVAILABLE_TOOLS.get(item.name)\n",
    "            if not tool_fn:\n",
    "                continue\n",
    "            args = _parse_arguments(item.arguments)\n",
    "            try:\n",
    "                result_payload = tool_fn(**args)\n",
    "            except TypeError as exc:\n",
    "                result_payload = {\"success\": False, \"error\": str(exc)}\n",
    "            json_payload = json.dumps(result_payload)\n",
    "            call_outputs.append({\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json_payload,\n",
    "            })\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json_payload,\n",
    "            })\n",
    "\n",
    "    final = await async_client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        instructions=\"Summarize the tool findings clearly for the user.\",\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(final)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"input_list\": input_list,\n",
    "        \"tool_outputs\": call_outputs,\n",
    "        \"assistant_text\": final.output_text,\n",
    "        \"responses\": transcript,\n",
    "    }\n",
    "\n",
    "async_demo = await run_assistant_async(\"Can you read my Capricorn horoscope?\")\n",
    "print(async_demo[\"assistant_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd7054",
   "metadata": {},
   "source": [
    "### Built-In Responses API Tools at a Glance\n",
    "\n",
    "- `code_interpreter`: Executes Python snippets in a managed sandbox and returns stdout, plots, and files for data wrangling workflows.\n",
    "- `file_search`: Lets the assistant scan embeddings-indexed documents you have uploaded, returning citations or extracted passages.\n",
    "- `function` (custom tools): The adapter we are using hereâ€”describe your own callable endpoints and the model will request them when it needs external data.\n",
    "- `web_search` (beta regions): Allows the model to surface fresh public information, subject to your deployment and safety filters.\n",
    "- `response.create` helpers: Chain multiple tool calls by continuing to send the growing transcript via the `input` list, just like the horoscope demo below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd68b1",
   "metadata": {},
   "source": [
    "#### Example: Using Built-In Web Search\n",
    "\n",
    "Here's a minimal call that lets the model reach out for fresh information. The `web_search` tool requires no custom setupâ€”just declare it, ask your question, and the Responses API handles the search call and citations automatically (ensure the feature is available in your region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb14558",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_demo = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Find the latest news about breakthroughs in quantum computing and summarize one key development.\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(web_search_demo.model_dump_json(indent=2))\n",
    "print(\"\\nSummary:\")\n",
    "print(web_search_demo.output_text or \"(No text output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fac839",
   "metadata": {},
   "source": [
    "## âœ… Key Takeaways\n",
    "\n",
    "âœ“ Tool calling bridges model creativity with your live systems.\n",
    "\n",
    "âœ“ Built-in tools like `web_search`, `code_interpreter`, and `file_search` give you zero-setup superpowersâ€”mix them with your custom functions for richer assistants.\n",
    "\n",
    "âœ“ Always describe tools precisely with JSON Schema so the assistant knows when to use them.\n",
    "\n",
    "âœ“ You must execute tool logic yourselfâ€”validate inputs, handle errors, and return structured output.\n",
    "\n",
    "âœ“ Wrap the request â†’ tool â†’ response loop in helpers to keep production agents tidy.\n",
    "\n",
    "â€”\n",
    "\n",
    "**Great work!** You now have the blueprint for assistants that can reason, fetch, and act with confidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-level-up-in-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
