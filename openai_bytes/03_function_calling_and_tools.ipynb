{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50920683",
   "metadata": {},
   "source": [
    "# Byte #3: Function Calling with OpenAI (Agents in Action) ðŸ”§\n",
    "\n",
    "**â±ï¸ Time to Complete: 10-15 minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc11533",
   "metadata": {},
   "source": [
    "Welcome back to hero HQ! By now you can talk to models, reason through async calls, and keep conversations alive. In this byte you will teach an assistant to reach beyond the model and use trusted toolsâ€”perfect for building production-ready copilots that can look up data, run calculations, or trigger workflows on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66519459",
   "metadata": {},
   "source": [
    "## Why Function Calling?\n",
    "\n",
    "Models donâ€™t automatically know your private knowledge base, inventory numbers, or the latest sensor readings. Function calling lets you expose safe, well-defined functions so an assistant can fetch facts, perform actions, or orchestrate other systemsâ€”all while you stay in control of what can be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14961a31",
   "metadata": {},
   "source": [
    "### Core Concepts\n",
    "\n",
    "- **Tool** â†’ A function you register with the model (JSON schema describes inputs).\n",
    "- **Tool call** â†’ The model requests a tool by name with arguments when it needs external help.\n",
    "- **Tool result** â†’ Your application executes the function, then replies with the output so the model can finish its answer.\n",
    "- **Guardrails** â†’ You decide which tools exist and validate every call before running it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd462f5",
   "metadata": {},
   "source": [
    "### How Tool Calling Works (Quick View)\n",
    "\n",
    "1. You describe every tool with JSON Schema so the assistant knows the contract.\n",
    "2. The model decides whether to call a tool and returns the requested name plus arguments.\n",
    "3. Your code validates the request, executes the function, and packages the result.\n",
    "4. You send that tool output back through the `input` list so the model can finish its answer.\n",
    "\n",
    "_The assistant never runs code on its ownâ€”you stay in the loop for every call._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0b8ba",
   "metadata": {},
   "source": [
    "## Setup Checklist\n",
    "\n",
    "1. Activate your project virtual environment.\n",
    "2. Install dependencies once with `uv pip install -e .` so the OpenAI SDK and dotenv helper are ready.\n",
    "3. Confirm your `.env` file has a valid `OPENAI_API_KEY` (and restart the kernel after edits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bab474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Load environment variables so the OpenAI SDK can find OPENAI_API_KEY\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "print(\"âœ… OpenAI client ready for tool calling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e99f88",
   "metadata": {},
   "source": [
    "## Step 1: Why Use Tools for Math?\n",
    "\n",
    "Large language models are fluent with words but can drift when arithmetic gets tricky. Asking for the cube root of 343 and the square root of 576 sounds simple, yet minor sampling randomness or a rushed internal calculation can still produce mistakes. Instead of trusting the guess, we can hand the computation to deterministic Python helpers via tool calling and let the model focus on the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_root(operation: str, value: float) -> dict:\n",
    "    \"\"\"Return precise square or cube roots using Python math helpers.\"\"\"\n",
    "    if operation == \"square_root\":\n",
    "        result = math.sqrt(value)\n",
    "    elif operation == \"cube_root\":\n",
    "        result = math.copysign(abs(value) ** (1 / 3), value)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operation: {operation}\")\n",
    "    return {\n",
    "        \"operation\": operation,\n",
    "        \"value\": value,\n",
    "        \"result\": result,\n",
    "    }\n",
    "\n",
    "AVAILABLE_TOOLS = {\"calculate_root\": calculate_root}\n",
    "print(\"ðŸ› ï¸ Local tools registered: \" + \", \".join(AVAILABLE_TOOLS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59a896",
   "metadata": {},
   "source": [
    "## Step 2: Describe the Math Tool\n",
    "\n",
    "The assistant needs a precise contract to know how to call `calculate_root`. We'll publish a JSON Schema that constrains the `operation` to either `square_root` or `cube_root` and requires a numeric `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_root\",\n",
    "        \"description\": \"Compute the square root or cube root of a number using Python math.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"square_root\", \"cube_root\"],\n",
    "                    \"description\": \"Choose whether to calculate a square root or cube root.\",\n",
    "                },\n",
    "                \"value\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Positive or negative number to process.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"operation\", \"value\"],\n",
    "        },\n",
    "    },\n",
    " ]\n",
    "print(json.dumps(tools, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44cc74",
   "metadata": {},
   "source": [
    "## Step 3: Let the Assistant Delegate the Roots\n",
    "\n",
    "We'll ask for two values in one sentence: the square root of 576 and the cube root of 343. The model will parse the request, decide to call `calculate_root` for each portion, and we will execute the calculations so the final reply is exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Please share the square root of 576 and the cube root of 343.\"\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": question}\n",
    "        ],\n",
    "    }\n",
    " ]\n",
    "\n",
    "# First round-trip: ask the model for help and let it decide if tools are needed\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    " )\n",
    "\n",
    "def _serialize_output_item(item):\n",
    "    \"\"\"Convert SDK output objects into dictionaries we can send back to the API.\"\"\"\n",
    "    payload = json.loads(item.model_dump_json())\n",
    "    payload.pop(\"status\", None)\n",
    "    return payload\n",
    "\n",
    "# Append everything the model just produced (tool calls, thoughts, etc.) back into the transcript\n",
    "input_list += [_serialize_output_item(item) for item in response.output]\n",
    "\n",
    "# Execute each tool request locally and push the results to the transcript\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\" and item.name == \"calculate_root\":\n",
    "        args = item.arguments\n",
    "        if isinstance(args, str):\n",
    "            args = json.loads(args or \"{}\")\n",
    "        elif args is None:\n",
    "            args = {}\n",
    "        tool_result = calculate_root(**args)\n",
    "        input_list.append({\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": item.call_id,\n",
    "            \"output\": json.dumps(tool_result),\n",
    "        })\n",
    "\n",
    "print(\"Final input transcript:\")\n",
    "print(json.dumps(input_list, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2844c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second round-trip: resend the enriched transcript so the model can compose the final answer\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"Summarize the tool outputs with the exact numeric answers.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    " )\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + (response.output_text or \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1080b",
   "metadata": {},
   "source": [
    "### Flow Recap\n",
    "\n",
    "1. **Send** the user request along with the `calculate_root` schema.\n",
    "2. **Inspect** the assistant outputâ€”each `function_call` includes the operation (`square_root` or `cube_root`) plus the numeric value it extracted from the question.\n",
    "3. **Respond** by running the Python helper and pushing a `function_call_output` back into the transcript.\n",
    "4. **Read** the assistantâ€™s final narrative, which now quotes the precise results computed in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228630a4",
   "metadata": {},
   "source": [
    "### Step-by-Step Decision Trace\n",
    "\n",
    "1. **Tool awareness**: Because the schema lists only `calculate_root`, the model knows that any precise math should go through that function.\n",
    "2. **Argument extraction**: While generating its first response, the model spots â€œsquare root of 576â€ and â€œcube root of 343,â€ mapping them to two calls with `operation` and `value` arguments.\n",
    "3. **Your execution**: Python evaluates both requestsâ€”`math.sqrt(576)` and the signed cube root of 343â€”returning exact floats.\n",
    "4. **Final message**: With those outputs stitched into the transcript, the model crafts a natural-language answer that cites the tool data instead of guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a8382",
   "metadata": {},
   "source": [
    "## Step 4: Wrap It in a Helper\n",
    "\n",
    "Encapsulate the pattern so services can reuse it. The helper below runs the complete loop and returns both the structured tool outputs and the assistant narration, guaranteeing every root comes from Python instead of a language-model guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_arguments(raw_args):\n",
    "    if isinstance(raw_args, str):\n",
    "        raw_args = raw_args or \"{}\"\n",
    "        return json.loads(raw_args)\n",
    "    return raw_args or {}\n",
    "\n",
    "def _serialize_output_item(item):\n",
    "    payload = json.loads(item.model_dump_json())\n",
    "    payload.pop(\"status\", None)\n",
    "    return payload\n",
    "\n",
    "def run_assistant(prompt: str, model: str = \"gpt-5-nano\") -> dict:\n",
    "    \"\"\"Run the Responses API tool-calling loop and return structured data.\"\"\"\n",
    "    transcript = []\n",
    "    input_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    initial = client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(initial)\n",
    "    input_list += [_serialize_output_item(item) for item in initial.output]\n",
    "\n",
    "    call_outputs = []\n",
    "    for item in initial.output:\n",
    "        if item.type == \"function_call\":\n",
    "            tool_fn = AVAILABLE_TOOLS.get(item.name)\n",
    "            args = _parse_arguments(item.arguments)\n",
    "            if not tool_fn:\n",
    "                result_payload = {\"success\": False, \"error\": f\"Unknown tool: {item.name}\"}\n",
    "            else:\n",
    "                try:\n",
    "                    result_payload = tool_fn(**args)\n",
    "                except TypeError as exc:\n",
    "                    result_payload = {\"success\": False, \"error\": str(exc)}\n",
    "            serialized_result = json.dumps(result_payload)\n",
    "            call_outputs.append({\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": serialized_result,\n",
    "            })\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": serialized_result,\n",
    "            })\n",
    "\n",
    "    final = client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        instructions=\"Summarize the tool findings clearly for the user.\",\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(final)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"input_list\": input_list,\n",
    "        \"tool_outputs\": call_outputs,\n",
    "        \"assistant_text\": final.output_text,\n",
    "        \"responses\": transcript,\n",
    "    }\n",
    "\n",
    "demo = run_assistant(\"What are the square root of 1024 and the cube root of 64?\")\n",
    "print(demo[\"assistant_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b724e03",
   "metadata": {},
   "source": [
    "## Optional: Async Version\n",
    "\n",
    "Large agents often run in event loops. The async helper mirrors the same flow but awaits each network hop so you can orchestrate multiple assistants concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "async_client = AsyncOpenAI()\n",
    "\n",
    "async def run_assistant_async(prompt: str, model: str = \"gpt-5-nano\") -> dict:\n",
    "    \"\"\"Async variant that mirrors the cumulative input workflow.\"\"\"\n",
    "    transcript = []\n",
    "    input_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    initial = await async_client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(initial)\n",
    "    input_list += [_serialize_output_item(item) for item in initial.output]\n",
    "\n",
    "    call_outputs = []\n",
    "    for item in initial.output:\n",
    "        if item.type == \"function_call\":\n",
    "            tool_fn = AVAILABLE_TOOLS.get(item.name)\n",
    "            if not tool_fn:\n",
    "                continue\n",
    "            args = _parse_arguments(item.arguments)\n",
    "            try:\n",
    "                result_payload = tool_fn(**args)\n",
    "            except TypeError as exc:\n",
    "                result_payload = {\"success\": False, \"error\": str(exc)}\n",
    "            json_payload = json.dumps(result_payload)\n",
    "            call_outputs.append({\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json_payload,\n",
    "            })\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json_payload,\n",
    "            })\n",
    "\n",
    "    final = await async_client.responses.create(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        instructions=\"Summarize the tool findings clearly for the user.\",\n",
    "        input=input_list,\n",
    "    )\n",
    "    transcript.append(final)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"input_list\": input_list,\n",
    "        \"tool_outputs\": call_outputs,\n",
    "        \"assistant_text\": final.output_text,\n",
    "        \"responses\": transcript,\n",
    "    }\n",
    "\n",
    "async_demo = await run_assistant_async(\"Calculate the square root of 361 and the cube root of -512.\")\n",
    "print(async_demo[\"assistant_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd68b1",
   "metadata": {},
   "source": [
    "## When Custom Tools Aren't Needed\n",
    "\n",
    "Many workflows already ship in the Responses API. After completing the math walkthrough, scroll to the end of this notebook for the built-in `web_search` demo. It highlights how you can mix and match: rely on turnkey tools like `web_search`, `code_interpreter`, or `file_search` for standard capabilities, and reserve custom functions such as `calculate_root` for domain-specific logic.\n",
    "\n",
    "## Built-In Tools in Action\n",
    "\n",
    "You do not need to craft a new function for every capability. The Responses API exposes several built-in tools you can toggle on when deploying assistants. The example below reuses `web_search` to surface the latest quantum-computing headlineâ€”no custom Python required aside from recording the result. (Feature availability varies by region, so run this cell to confirm access in your account.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_demo = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Find one headline-worthy quantum computing breakthrough from this month and summarize it.\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(web_search_demo.model_dump_json(indent=2))\n",
    "print(\"\\nSummary:\")\n",
    "print(web_search_demo.output_text or \"(No text output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fac839",
   "metadata": {},
   "source": [
    "## âœ… Key Takeaways\n",
    "\n",
    "âœ“ Tool calling bridges model creativity with your live systems.\n",
    "\n",
    "âœ“ Built-in tools like `web_search`, `code_interpreter`, and `file_search` give you zero-setup superpowersâ€”mix them with your custom functions for richer assistants.\n",
    "\n",
    "âœ“ Always describe tools precisely with JSON Schema so the assistant knows when to use them.\n",
    "\n",
    "âœ“ You must execute tool logic yourselfâ€”validate inputs, handle errors, and return structured output.\n",
    "\n",
    "âœ“ Wrap the request â†’ tool â†’ response loop in helpers to keep production agents tidy.\n",
    "\n",
    "â€”\n",
    "\n",
    "**Great work!** You now have the blueprint for assistants that can reason, fetch, and act with confidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-level-up-in-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
